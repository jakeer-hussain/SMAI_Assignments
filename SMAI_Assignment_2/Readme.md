# SMAI Assignment 2 - IIIT Hyderabad

This repository contains the complete implementation of **Assignment 2** for the course *Statistical Methods in AI* (SMAI), offered at IIIT-Hyderabad, under the guidance of **Prof. Vineet Gandhi**.

The assignment demonstrates a comprehensive understanding of core machine learning models including:
- Multi-Layer Perceptron (MLP)
- Gaussian Mixture Models (GMM)
- Principal Component Analysis (PCA)
- Autoencoder
- Variational Autoencoder (VAE)

## üìÅ Structure

Each section of the assignment is implemented in a dedicated Jupyter Notebook, with code and visualizations integrated with markdown cells for clear documentation and results.

### üîπ Multi-Layer Perceptron (MLP)
1. **Symbol Classification (Multi-class)**
   - Implemented MLP from scratch
   - 10-fold cross-validation
   - Various activation functions (Sigmoid, Tanh, ReLU) and optimizers (SGD, Batch, Mini-Batch)
   - Dataset: Handwritten historical symbols

2. **House Price Prediction in Bangalore (Regression)**
   - Data preprocessing (missing values, outliers)
   - MLP regression model from scratch
   - Evaluation metrics: MSE, RMSE, R¬≤

3. **News Article Classification (Multi-label)**
   - Text preprocessing and TF-IDF implementation from scratch
   - Multi-label binarization
   - Custom MLP architecture for multi-label classification

---

### üîπ Gaussian Mixture Model (GMM)
- GMM implemented from scratch
- Medical image segmentation (Gray Matter, White Matter, CSF)
- Analysis using ITK-SNAP
- Intensity vs Frequency and GMM distribution plots

---

### üîπ Principal Component Analysis (PCA)
- PCA implementation from scratch (Eigen decomposition)
- Dimensionality reduction on MNIST
- Explained variance analysis and reconstruction
- MLP classification with and without PCA

---

### üîπ Autoencoder
- PyTorch-based implementation
- Anomaly detection using reconstruction error
- Evaluation using Precision, Recall, F1-score
- Analysis of various bottleneck sizes using ROC-AUC

---

### üîπ Variational Autoencoder (VAE)
- Implemented VAE using PyTorch
- Latent space visualization
- Experiments with and without reconstruction/KL loss
- Sampling from latent space grids (BCE and MSE losses)

---

## üõ†Ô∏è Technologies Used
- Python
- Jupyter Notebook
- NumPy, Matplotlib, scikit-learn
- PyTorch
- Torchvision
- ITK-SNAP (for image segmentation visualization)

## üìä Results
- Extensive visualizations and metric tracking included within notebooks
- Plots: Training curves, accuracy trends, ROC curves, PCA projections, etc.
- Each model‚Äôs performance and tuning process is well-documented

---

## üìÅ Submission Instructions Followed
- ‚úÖ Implemented required parts from scratch
- ‚úÖ Used PyTorch only where allowed (AE & VAE)
- ‚úÖ Included all observations, plots, and analysis within the notebooks

---

## üß† Author
- Implemented by: *P. Jakeer Hussain* 
- Institute: IIIT Hyderabad
- Course: Statistical Methods in AI (Spring 2025)
